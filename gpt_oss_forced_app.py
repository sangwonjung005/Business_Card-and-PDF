import os
import streamlit as st
from PyPDF2 import PdfReader
import numpy as np
import time
import re
import requests
from PIL import Image
import pytesseract
import json
from typing import Dict, List, Optional
import base64
from io import BytesIO

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="GPT-OSS Only Business Card OCR & PDF Assistant",
    page_icon="ğŸ’¼",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë°ì´í„° ì €ì¥ íŒŒì¼ ê²½ë¡œ
DATA_DIR = "app_data"
BUSINESS_CARDS_FILE = os.path.join(DATA_DIR, "business_cards.json")
CONVERSATION_FILE = os.path.join(DATA_DIR, "conversation_history.json")

# ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(DATA_DIR, exist_ok=True)

def save_data_to_file(data, filename):
    """ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        st.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
        return False

def load_data_from_file(filename, default_value):
    """JSON íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    try:
        if os.path.exists(filename):
            with open(filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        return default_value
    except Exception as e:
        st.warning(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return default_value

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (íŒŒì¼ì—ì„œ ë¡œë“œ)
if "business_cards" not in st.session_state:
    st.session_state.business_cards = load_data_from_file(BUSINESS_CARDS_FILE, [])
if "pdf_docs" not in st.session_state:
    st.session_state.pdf_docs = None
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = load_data_from_file(CONVERSATION_FILE, [])

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: #ffffff;
    }
    
    .card {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 15px;
        padding: 20px;
        margin: 10px 0;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.2);
    }
    
    .business-card {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        border-radius: 15px;
        padding: 20px;
        margin: 10px 0;
        color: white;
        box-shadow: 0 8px 32px rgba(0,0,0,0.3);
    }
    
    .pdf-section {
        background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        border-radius: 15px;
        padding: 20px;
        margin: 10px 0;
        color: #333;
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 10px 25px;
        font-weight: bold;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.3);
    }
</style>
""", unsafe_allow_html=True)

def call_gpt_oss_api(prompt: str) -> str:
    """AI API í˜¸ì¶œ - ì—¬ëŸ¬ ëª¨ë¸ ì‹œë„ (Gemma í¬í•¨)"""
    
    # í•µì‹¬ ëª¨ë¸ë“¤ (GPT-OSS + Gemma + ê¸°ë³¸)
    models = [
        # GPT-OSS ëª¨ë¸ë“¤ (ìš°ì„ ìˆœìœ„)
        "openai/gpt-oss-20b",
        "openai/gpt-oss-120b",
        # Gemma ëª¨ë¸ë“¤ (ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸)
        "google/gemma-3-270m",
        "google/gemma-2b",
        "google/gemma-7b",
        # ê¸°ë³¸ ì•ˆì • ëª¨ë¸
        "microsoft/DialoGPT-medium"
    ]
    
    for model in models:
        try:
            st.write(f"ğŸ”„ Trying {model}...")
            
            # Hugging Face API ì‹œë„
            API_URL = f"https://api-inference.huggingface.co/models/{model}"
            headers = {"Content-Type": "application/json"}
            
            # ëª¨ë¸ë³„ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ í˜•ì‹
            if "gpt-oss" in model:
                payload = {
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": 500,
                        "temperature": 0.3,
                        "do_sample": True
                    }
                }
            elif "gemma" in model:
                # Gemma ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸ í˜•ì‹
                payload = {
                    "inputs": f"<start_of_turn>user\n{prompt}<end_of_turn>\n<start_of_turn>model\n",
                    "parameters": {
                        "max_new_tokens": 500,
                        "temperature": 0.3,
                        "do_sample": True,
                        "top_p": 0.9
                    }
                }
            elif "dialo" in model.lower():
                # DialoGPT ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸ í˜•ì‹
                payload = {
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": 300,
                        "temperature": 0.7,
                        "do_sample": True,
                        "pad_token_id": 50256
                    }
                }
            else:
                # ì¼ë°˜ GPT ëª¨ë¸ë“¤
                payload = {
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": 200,
                        "temperature": 0.7,
                        "do_sample": True
                    }
                }
            
            response = requests.post(API_URL, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    generated_text = result[0].get('generated_text', '')
                    # í”„ë¡¬í”„íŠ¸ ì œê±°
                    if prompt in generated_text:
                        generated_text = generated_text.replace(prompt, '').strip()
                    # Gemma íŠ¹ë³„ ì²˜ë¦¬
                    if "gemma" in model:
                        # Gemma ì‘ë‹µì—ì„œ ëª¨ë¸ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                        if "<start_of_turn>model\n" in generated_text:
                            generated_text = generated_text.split("<start_of_turn>model\n")[-1]
                        if "<end_of_turn>" in generated_text:
                            generated_text = generated_text.split("<end_of_turn>")[0]
                    st.success(f"âœ… {model} ì„±ê³µ!")
                    return generated_text
                else:
                    st.warning(f"âš ï¸ {model}: ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
            else:
                st.warning(f"âš ï¸ {model}: HTTP {response.status_code}")
                
        except Exception as e:
            st.warning(f"âš ï¸ {model}: {str(e)}")
            continue
    
    # Hugging Face ì‹¤íŒ¨ì‹œ Ollama ì‹œë„ (ì„ íƒì‚¬í•­)
    st.info("ğŸ”„ Hugging Face ì‹¤íŒ¨. Ollama Gemma ì‹œë„...")
    
    ollama_models = ["gemma3:270m", "gemma2:2b", "gemma2:7b"]
    
    for ollama_model in ollama_models:
        try:
            st.write(f"ğŸ”„ Trying Ollama {ollama_model}...")
            
            # Ollama API í˜¸ì¶œ
            ollama_url = "http://localhost:11434/api/generate"
            ollama_payload = {
                "model": ollama_model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,
                    "top_p": 0.9,
                    "num_predict": 500
                }
            }
            
            response = requests.post(ollama_url, json=ollama_payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                generated_text = result.get('response', '')
                if generated_text:
                    st.success(f"âœ… Ollama {ollama_model} ì„±ê³µ!")
                    return generated_text
                else:
                    st.warning(f"âš ï¸ Ollama {ollama_model}: ë¹ˆ ì‘ë‹µ")
            else:
                st.warning(f"âš ï¸ Ollama {ollama_model}: HTTP {response.status_code}")
                
        except Exception as e:
            st.warning(f"âš ï¸ Ollama {ollama_model}: {str(e)}")
            continue
    
    # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì‘ë‹µ
    st.error("âŒ ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨.")
    return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ AI ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

def extract_business_card_info(image):
    """ëª…í•¨ ì´ë¯¸ì§€ì—ì„œ ì •ë³´ ì¶”ì¶œ"""
    try:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (PIL ì‚¬ìš©)
        gray_image = image.convert('L')
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        width, height = gray_image.size
        if width > 1200:
            ratio = 1200 / width
            new_width = 1200
            new_height = int(height * ratio)
            gray_image = gray_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # OCR ì‹¤í–‰
        text = pytesseract.image_to_string(gray_image, lang='kor+eng')
        
        # GPT-OSSë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë³´ êµ¬ì¡°í™”
        structured_info = structure_business_card_info(text)
        
        return structured_info
        
    except Exception as e:
        st.error(f"ëª…í•¨ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def structure_business_card_info(raw_text):
    """GPT-OSSë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…í•¨ ì •ë³´ë¥¼ êµ¬ì¡°í™”"""
    try:
        prompt = f"""
ë‹¤ìŒ ëª…í•¨ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:

{raw_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{{
    "name": "ì´ë¦„",
    "title": "ì§ì±…",
    "company": "íšŒì‚¬ëª…",
    "email": "ì´ë©”ì¼",
    "phone": "ì „í™”ë²ˆí˜¸",
    "mobile": "íœ´ëŒ€í°",
    "address": "ì£¼ì†Œ",
    "website": "ì›¹ì‚¬ì´íŠ¸",
    "department": "ë¶€ì„œ"
}}

ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° nullë¡œ í‘œì‹œí•˜ì„¸ìš”.
"""
        
        # GPT-OSS API í˜¸ì¶œ
        response = call_gpt_oss_api(prompt)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            if json_start != -1 and json_end != -1:
                json_str = response[json_start:json_end]
                return json.loads(json_str)
        except:
            pass
        
        # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
        return {
            "name": "ì¶”ì¶œ ì‹¤íŒ¨",
            "title": None,
            "company": None,
            "email": None,
            "phone": None,
            "mobile": None,
            "address": None,
            "website": None,
            "department": None,
            "raw_text": raw_text,
            "gpt_oss_response": response
        }
        
    except Exception as e:
        return {"error": str(e), "raw_text": raw_text}

def read_pdf(file) -> str:
    """PDF ì½ê¸°"""
    text = ""
    reader = PdfReader(file)
    for page in reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text + "\n"
    return text

def chunk_text(text: str, chunk_size: int = 200, overlap: int = 50):
    """í…ìŠ¤íŠ¸ ì²­í‚¹"""
    words = text.split()
    chunks = []
    start = 0
    while start < len(words):
        chunk = " ".join(words[start : start + chunk_size])
        chunks.append(chunk)
        start += chunk_size - overlap
    return chunks

def get_context(question: str, docs: list) -> str:
    """ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
    if not docs:
        return ""
    
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
    question_words = set(question.lower().split())
    best_chunks = []
    
    for i, doc in enumerate(docs[:5]):
        doc_words = set(doc.lower().split())
        overlap = len(question_words.intersection(doc_words))
        if overlap > 0:
            best_chunks.append(doc)
    
    return "\n\n".join(best_chunks[:3]) if best_chunks else docs[0] if docs else ""

def generate_answer(question: str, context: str) -> str:
    """GPT-OSSë¥¼ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±"""
    try:
        if context:
            prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ì°¸ê³  ì •ë³´:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
        else:
            prompt = question
        
        response = call_gpt_oss_api(prompt)
        return response
        
    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

# ë©”ì¸ UI
st.title("ğŸ’¼ AI Business Card OCR & PDF Assistant")
st.markdown("**GPT-OSS + Gemma + ì˜¤í”ˆì†ŒìŠ¤ AI** - ëª…í•¨ OCRê³¼ PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ")

# ê¸°ëŠ¥ ì„ íƒ
selected_function = st.selectbox(
    "ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”:",
    ["ğŸ“‡ ëª…í•¨ OCR", "ğŸ“„ PDF RAG", "ğŸ¤– AI ì±„íŒ…", "ğŸ’¬ ëŒ€í™” ê¸°ë¡"],
    index=0
)

if selected_function == "ğŸ“‡ ëª…í•¨ OCR":
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.header("ğŸ“‡ ëª…í•¨ OCR (AI)")
    st.write("ëª…í•¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ GPT-OSS, Gemma ë˜ëŠ” ê¸°íƒ€ AIê°€ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    uploaded_image = st.file_uploader(
        "ëª…í•¨ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
        type=['png', 'jpg', 'jpeg'],
        help="ëª…í•¨ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_image is not None:
        image = Image.open(uploaded_image)
        st.image(image, caption="ì—…ë¡œë“œëœ ëª…í•¨", use_column_width=True)
        
        if st.button("ğŸ” AIë¡œ ëª…í•¨ ì •ë³´ ì¶”ì¶œ", type="primary"):
            with st.spinner("AIê°€ ëª…í•¨ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                card_info = extract_business_card_info(image)
                
                if card_info and "error" not in card_info:
                    # ëª…í•¨ ì •ë³´ë¥¼ ì„¸ì…˜ì— ì €ì¥
                    card_info["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
                    st.session_state.business_cards.append(card_info)
                    
                    # íŒŒì¼ì— ì˜êµ¬ ì €ì¥
                    save_data_to_file(st.session_state.business_cards, BUSINESS_CARDS_FILE)
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.markdown('<div class="business-card">', unsafe_allow_html=True)
                    st.subheader("ğŸ“‹ AI ì¶”ì¶œ ê²°ê³¼")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if card_info.get("name"):
                            st.write(f"**ì´ë¦„:** {card_info['name']}")
                        if card_info.get("title"):
                            st.write(f"**ì§ì±…:** {card_info['title']}")
                        if card_info.get("company"):
                            st.write(f"**íšŒì‚¬:** {card_info['company']}")
                        if card_info.get("department"):
                            st.write(f"**ë¶€ì„œ:** {card_info['department']}")
                    
                    with col2:
                        if card_info.get("email"):
                            st.write(f"**ì´ë©”ì¼:** {card_info['email']}")
                        if card_info.get("phone"):
                            st.write(f"**ì „í™”:** {card_info['phone']}")
                        if card_info.get("mobile"):
                            st.write(f"**íœ´ëŒ€í°:** {card_info['mobile']}")
                        if card_info.get("website"):
                            st.write(f"**ì›¹ì‚¬ì´íŠ¸:** {card_info['website']}")
                    
                    if card_info.get("address"):
                        st.write(f"**ì£¼ì†Œ:** {card_info['address']}")
                    
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    st.success("âœ… AIê°€ ëª…í•¨ ì •ë³´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error("AI ëª…í•¨ ì •ë³´ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ëª…í•¨ì— ëŒ€í•œ ì§ˆë¬¸ ê¸°ëŠ¥
    if st.session_state.business_cards:
        st.subheader("ğŸ’¬ ëª…í•¨ì— ëŒ€í•´ AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°")
        st.write("ì¶”ì¶œëœ ëª…í•¨ ì •ë³´ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”.")
        
        # ëª…í•¨ ì„ íƒ
        selected_card_index = st.selectbox(
            "ì§ˆë¬¸í•  ëª…í•¨ì„ ì„ íƒí•˜ì„¸ìš”:",
            range(len(st.session_state.business_cards)),
            format_func=lambda x: f"{st.session_state.business_cards[x].get('name', 'Unknown')} - {st.session_state.business_cards[x].get('company', 'Unknown')}"
        )
        
        if selected_card_index is not None:
            selected_card = st.session_state.business_cards[selected_card_index]
            
            # ì„ íƒëœ ëª…í•¨ ì •ë³´ í‘œì‹œ
            with st.expander("ì„ íƒëœ ëª…í•¨ ì •ë³´"):
                st.json(selected_card)
            
            # ì§ˆë¬¸ ì…ë ¥
            card_question = st.text_input(
                "ëª…í•¨ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:",
                placeholder="ì˜ˆ: ì´ ì‚¬ëŒì˜ ì—°ë½ì²˜ëŠ”? íšŒì‚¬ ì£¼ì†ŒëŠ”? ì§ì±…ì€?",
                key="card_question"
            )
            
            if st.button("ğŸ¤– AI ë‹µë³€ ìƒì„±", type="primary", key="card_question_button") and card_question:
                with st.spinner("AIê°€ ëª…í•¨ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                    # ëª…í•¨ ì •ë³´ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
                    card_context = f"""
ëª…í•¨ ì •ë³´:
ì´ë¦„: {selected_card.get('name', 'N/A')}
ì§ì±…: {selected_card.get('title', 'N/A')}
íšŒì‚¬: {selected_card.get('company', 'N/A')}
ì´ë©”ì¼: {selected_card.get('email', 'N/A')}
ì „í™”: {selected_card.get('phone', 'N/A')}
íœ´ëŒ€í°: {selected_card.get('mobile', 'N/A')}
ì£¼ì†Œ: {selected_card.get('address', 'N/A')}
ì›¹ì‚¬ì´íŠ¸: {selected_card.get('website', 'N/A')}
ë¶€ì„œ: {selected_card.get('department', 'N/A')}
"""
                    
                    # AI ë‹µë³€ ìƒì„±
                    card_answer = generate_answer(card_question, card_context)
                    
                    # ëŒ€í™” ê¸°ë¡ì— ì €ì¥
                    conversation_entry = {
                        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                        "question": card_question,
                        "answer": card_answer,
                        "context": f"ëª…í•¨ ì •ë³´: {selected_card.get('name', 'Unknown')}",
                        "type": "business_card_qa"
                    }
                    st.session_state.conversation_history.append(conversation_entry)
                    
                    # íŒŒì¼ì— ì˜êµ¬ ì €ì¥
                    save_data_to_file(st.session_state.conversation_history, CONVERSATION_FILE)
                    
                    # ë‹µë³€ í‘œì‹œ
                    st.markdown('<div class="business-card">', unsafe_allow_html=True)
                    st.subheader("ğŸ¤– AI ë‹µë³€")
                    st.write(card_answer)
                    st.markdown('</div>', unsafe_allow_html=True)
    
    # ì €ì¥ëœ ëª…í•¨ ëª©ë¡
    if st.session_state.business_cards:
        st.subheader("ğŸ“š ì €ì¥ëœ ëª…í•¨ ëª©ë¡")
        for i, card in enumerate(st.session_state.business_cards):
            with st.expander(f"ëª…í•¨ {i+1}: {card.get('name', 'Unknown')} - {card.get('company', 'Unknown')}"):
                st.json(card)
    st.markdown('</div>', unsafe_allow_html=True)

elif selected_function == "ğŸ“„ PDF RAG":
    st.markdown('<div class="pdf-section">', unsafe_allow_html=True)
    st.header("ğŸ“„ PDF RAG (AI)")
    st.write("PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•˜ë©´ GPT-OSS, Gemma ë˜ëŠ” ê¸°íƒ€ AIê°€ ë‹µë³€í•©ë‹ˆë‹¤.")
    
    uploaded_pdf = st.file_uploader(
        "PDF íŒŒì¼ ì—…ë¡œë“œ",
        type=['pdf'],
        help="PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_pdf is not None:
        with st.spinner("PDFë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            pdf_text = read_pdf(uploaded_pdf)
            if pdf_text:
                chunks = chunk_text(pdf_text)
                st.session_state.pdf_docs = chunks
                st.success(f"âœ… PDF ì²˜ë¦¬ ì™„ë£Œ! {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
                
                # PDF ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ğŸ“– PDF ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
                    st.text_area("PDF ë‚´ìš©", pdf_text[:1000] + "...", height=200, disabled=True)
    
    # ì§ˆë¬¸ ì…ë ¥
    if st.session_state.pdf_docs:
        st.subheader("ğŸ’¬ PDFì— ëŒ€í•´ AIì—ê²Œ ì§ˆë¬¸í•˜ê¸°")
        
        question = st.text_input(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
            placeholder="PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."
        )
        
        if st.button("ğŸ¤– AI ë‹µë³€ ìƒì„±", type="primary") and question:
            with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                context = get_context(question, st.session_state.pdf_docs)
                
                # GPT-OSS ë‹µë³€ ìƒì„±
                answer = generate_answer(question, context)
                
                # ëŒ€í™” ê¸°ë¡ì— ì €ì¥
                conversation_entry = {
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "question": question,
                    "answer": answer,
                    "context": context[:200] + "..." if len(context) > 200 else context,
                    "type": "pdf_rag"
                }
                st.session_state.conversation_history.append(conversation_entry)
                
                # íŒŒì¼ì— ì˜êµ¬ ì €ì¥
                save_data_to_file(st.session_state.conversation_history, CONVERSATION_FILE)
                
                # ë‹µë³€ í‘œì‹œ
                st.markdown('<div class="card">', unsafe_allow_html=True)
                st.subheader("ğŸ¤– AI ë‹µë³€")
                st.write(answer)
                
                if context:
                    with st.expander("ğŸ“„ ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸"):
                        st.text(context)
                
                st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.info("ğŸ“„ PDFë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.markdown('</div>', unsafe_allow_html=True)

elif selected_function == "ğŸ¤– AI ì±„íŒ…":
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.header("ğŸ¤– AI ì±„íŒ…")
    st.write("GPT-OSS, Gemma ë˜ëŠ” ê¸°íƒ€ AIì™€ ììœ ë¡­ê²Œ ëŒ€í™”í•˜ì„¸ìš”.")
    
    # ì±„íŒ… ì…ë ¥
    chat_question = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
        placeholder="ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”...",
        key="chat_input"
    )
    
    if st.button("ğŸ¤– AI ë‹µë³€ ìƒì„±", type="primary", key="chat_button") and chat_question:
        with st.spinner("AIê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            # AI ë‹µë³€ ìƒì„±
            chat_answer = call_gpt_oss_api(chat_question)
            
            # ëŒ€í™” ê¸°ë¡ì— ì €ì¥
            conversation_entry = {
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "question": chat_question,
                "answer": chat_answer,
                "context": "ì¼ë°˜ ì±„íŒ…",
                "type": "chat"
            }
            st.session_state.conversation_history.append(conversation_entry)
            
            # íŒŒì¼ì— ì˜êµ¬ ì €ì¥
            save_data_to_file(st.session_state.conversation_history, CONVERSATION_FILE)
            
            # ë‹µë³€ í‘œì‹œ
            st.markdown('<div class="business-card">', unsafe_allow_html=True)
            st.subheader("ğŸ¤– AI ë‹µë³€")
            st.write(chat_answer)
            st.markdown('</div>', unsafe_allow_html=True)
    
    # ì±„íŒ… ì˜ˆì‹œ
    st.subheader("ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ")
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ì•ˆë…•í•˜ì„¸ìš”!", key="example1"):
            st.session_state.chat_input = "ì•ˆë…•í•˜ì„¸ìš”!"
            st.rerun()
        if st.button("ì˜¤ëŠ˜ ë‚ ì”¨ëŠ”?", key="example2"):
            st.session_state.chat_input = "ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë–¤ê°€ìš”?"
            st.rerun()
        if st.button("ì¬ë¯¸ìˆëŠ” ì´ì•¼ê¸° í•´ì¤˜", key="example3"):
            st.session_state.chat_input = "ì¬ë¯¸ìˆëŠ” ì´ì•¼ê¸°ë‚˜ ë†ë‹´ì„ í•´ì¤˜"
            st.rerun()
    
    with col2:
        if st.button("ì½”ë”© ë„ì›€", key="example4"):
            st.session_state.chat_input = "Pythonìœ¼ë¡œ ê°„ë‹¨í•œ ê³„ì‚°ê¸° ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤˜"
            st.rerun()
        if st.button("ìš”ë¦¬ ë ˆì‹œí”¼", key="example5"):
            st.session_state.chat_input = "ê¹€ì¹˜ì°Œê°œ ë§Œë“œëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤˜"
            st.rerun()
        if st.button("ì—¬í–‰ ì¶”ì²œ", key="example6"):
            st.session_state.chat_input = "í•œêµ­ì—ì„œ ê°€ë³¼ ë§Œí•œ ì—¬í–‰ì§€ ì¶”ì²œí•´ì¤˜"
            st.rerun()
    
    st.markdown('</div>', unsafe_allow_html=True)

elif selected_function == "ğŸ’¬ ëŒ€í™” ê¸°ë¡":
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.header("ğŸ’¬ AI ëŒ€í™” ê¸°ë¡")
    
    if st.session_state.conversation_history:
        for i, entry in enumerate(reversed(st.session_state.conversation_history)):
            # ëŒ€í™” íƒ€ì…ì— ë”°ë¥¸ ì•„ì´ì½˜
            if entry.get('type') == 'chat':
                icon = "ğŸ’¬"
                title = f"ì±„íŒ… {len(st.session_state.conversation_history) - i}"
            elif entry.get('type') == 'business_card_qa':
                icon = "ğŸ“‡"
                title = f"ëª…í•¨ ì§ˆë¬¸ {len(st.session_state.conversation_history) - i}"
            else:
                icon = "ğŸ“„"
                title = f"PDF ëŒ€í™” {len(st.session_state.conversation_history) - i}"
            
            with st.expander(f"{icon} {title}: {entry['question'][:50]}..."):
                st.write(f"**ì§ˆë¬¸:** {entry['question']}")
                st.write(f"**AI ë‹µë³€:** {entry['answer']}")
                st.write(f"**ì‹œê°„:** {entry['timestamp']}")
                st.write(f"**íƒ€ì…:** {entry.get('type', 'PDF RAG')}")
                
                if entry.get('context') and entry.get('context') != "ì¼ë°˜ ì±„íŒ…":
                    with st.expander("ì»¨í…ìŠ¤íŠ¸"):
                        st.text(entry['context'])
    else:
        st.info("ì•„ì§ AI ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
            st.session_state.conversation_history = []
            # íŒŒì¼ì—ì„œë„ ì‚­ì œ
            try:
                if os.path.exists(CONVERSATION_FILE):
                    os.remove(CONVERSATION_FILE)
                st.success("ëŒ€í™” ê¸°ë¡ì´ ì™„ì „íˆ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
            except:
                st.warning("íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    
    with col2:
        if st.button("ğŸ—‘ï¸ ëª…í•¨ ë°ì´í„° ì´ˆê¸°í™”"):
            st.session_state.business_cards = []
            # íŒŒì¼ì—ì„œë„ ì‚­ì œ
            try:
                if os.path.exists(BUSINESS_CARDS_FILE):
                    os.remove(BUSINESS_CARDS_FILE)
                st.success("ëª…í•¨ ë°ì´í„°ê°€ ì™„ì „íˆ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
            except:
                st.warning("íŒŒì¼ ì‚­ì œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” í†µê³„
with st.sidebar:
    st.header("ğŸ“Š AI í†µê³„")
    
    # ëª…í•¨ í†µê³„
    st.subheader("ğŸ“‡ ëª…í•¨")
    st.metric("ì €ì¥ëœ ëª…í•¨", len(st.session_state.business_cards))
    
    # PDF í†µê³„
    st.subheader("ğŸ“„ PDF")
    if st.session_state.pdf_docs:
        st.metric("ì²­í¬ ìˆ˜", len(st.session_state.pdf_docs))
    else:
        st.metric("ì²­í¬ ìˆ˜", 0)
    
    # ëŒ€í™” í†µê³„
    st.subheader("ğŸ’¬ ëŒ€í™”")
    st.metric("AI ëŒ€í™” ìˆ˜", len(st.session_state.conversation_history))
    
    st.markdown("---")
    
    # ë°ì´í„° ê´€ë¦¬ ì •ë³´
    st.header("ğŸ’¾ ë°ì´í„° ê´€ë¦¬")
    st.info(f"""
    **ğŸ“ ì €ì¥ ìœ„ì¹˜:** `{DATA_DIR}/`
    - ëª…í•¨ ë°ì´í„°: `business_cards.json`
    - ëŒ€í™” ê¸°ë¡: `conversation_history.json`
    
    **ğŸ”„ ìë™ ì €ì¥:** ëª¨ë“  ë°ì´í„°ëŠ” ìë™ìœ¼ë¡œ íŒŒì¼ì— ì €ì¥ë©ë‹ˆë‹¤.
    **ğŸ“± ì˜êµ¬ ë³´ì¡´:** ë¸Œë¼ìš°ì €ë¥¼ ë‹«ì•„ë„ ë°ì´í„°ê°€ ìœ ì§€ë©ë‹ˆë‹¤.
    """)
    
    st.markdown("---")
    
    # ê¸°ëŠ¥ ì„¤ëª…
    st.header("ğŸ”§ AI ê¸°ëŠ¥")
    st.write("""
    **ğŸ“‡ ëª…í•¨ OCR:**
    - ëª…í•¨ ì´ë¯¸ì§€ ì—…ë¡œë“œ
    - AI ì •ë³´ ì¶”ì¶œ (GPT-OSS, Gemma, DialoGPT)
    - êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥
    
    **ğŸ“„ PDF RAG:**
    - PDF ë¬¸ì„œ ì—…ë¡œë“œ
    - í…ìŠ¤íŠ¸ ì²­í‚¹
    - AI ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ
    
    **ğŸ¤– AI ì±„íŒ…:**
    - ììœ ë¡œìš´ AI ëŒ€í™”
    - ì§ˆë¬¸ ì˜ˆì‹œ ì œê³µ
    - ë‹¤ì–‘í•œ ì£¼ì œ ëŒ€í™”
    
    **ğŸ’¬ ëŒ€í™” ê¸°ë¡:**
    - AI ì§ˆë¬¸-ë‹µë³€ íˆìŠ¤í† ë¦¬
    - ì±„íŒ…/PDF ëŒ€í™” êµ¬ë¶„
    - ë©”ëª¨ë¦¬ ê´€ë¦¬
    """)
