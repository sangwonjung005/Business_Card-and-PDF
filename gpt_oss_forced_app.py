import os
import streamlit as st
from openai import OpenAI
from PyPDF2 import PdfReader
import numpy as np
import time
import re
import requests
from PIL import Image
import pytesseract
import json
from typing import Dict, List, Optional
import base64
from io import BytesIO

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="GPT-OSS Business Card OCR & PDF Assistant",
    page_icon="ğŸ’¼",
    layout="wide",
    initial_sidebar_state="expanded"
)

# OpenAI API í‚¤ ì„¤ì • (fallbackìš©)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    key_candidates = [
        os.path.join(os.path.dirname(__file__), "nocommit_key.txt"),
        os.path.join(os.path.dirname(os.path.dirname(__file__)), "nocommit_key.txt"),
    ]
    for cand in key_candidates:
        if os.path.isfile(cand):
            try:
                with open(cand, "r", encoding="utf-8") as f:
                    OPENAI_API_KEY = f.read().strip()
                break
            except Exception:
                pass

# OpenAI í´ë¼ì´ì–¸íŠ¸ (fallbackìš©)
client = OpenAI(api_key=OPENAI_API_KEY)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "business_cards" not in st.session_state:
    st.session_state.business_cards = []
if "pdf_docs" not in st.session_state:
    st.session_state.pdf_docs = None
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: #ffffff;
    }
    
    .card {
        background: rgba(255, 255, 255, 0.1);
        border-radius: 15px;
        padding: 20px;
        margin: 10px 0;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.2);
    }
    
    .business-card {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        border-radius: 15px;
        padding: 20px;
        margin: 10px 0;
        color: white;
        box-shadow: 0 8px 32px rgba(0,0,0,0.3);
    }
    
    .pdf-section {
        background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
        border-radius: 15px;
        padding: 20px;
        margin: 10px 0;
        color: #333;
    }
    
    .stButton > button {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 10px 25px;
        font-weight: bold;
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.3);
    }
</style>
""", unsafe_allow_html=True)

def call_gpt_oss_api(prompt: str) -> str:
    """GPT-OSS API í˜¸ì¶œ - ì—¬ëŸ¬ ëª¨ë¸ ì‹œë„"""
    
    # ë‹¤ì–‘í•œ GPT-OSS ëª¨ë¸ë“¤
    gpt_oss_models = [
        "openai/gpt-oss-20b",
        "openai/gpt-oss-120b",
        "microsoft/DialoGPT-medium",
        "gpt2",
        "EleutherAI/gpt-neo-125M",
        "microsoft/DialoGPT-small"
    ]
    
    for model in gpt_oss_models:
        try:
            st.write(f"ğŸ”„ Trying {model}...")
            
            API_URL = f"https://api-inference.huggingface.co/models/{model}"
            headers = {"Content-Type": "application/json"}
            
            # ëª¨ë¸ë³„ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ í˜•ì‹
            if "gpt-oss" in model:
                payload = {
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": 500,
                        "temperature": 0.3,
                        "do_sample": True
                    }
                }
            else:
                payload = {
                    "inputs": prompt,
                    "parameters": {
                        "max_new_tokens": 200,
                        "temperature": 0.7,
                        "do_sample": True
                    }
                }
            
            response = requests.post(API_URL, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if isinstance(result, list) and len(result) > 0:
                    generated_text = result[0].get('generated_text', '')
                    # í”„ë¡¬í”„íŠ¸ ì œê±°
                    if prompt in generated_text:
                        generated_text = generated_text.replace(prompt, '').strip()
                    st.success(f"âœ… {model} ì„±ê³µ!")
                    return generated_text
                else:
                    st.warning(f"âš ï¸ {model}: ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜")
            else:
                st.warning(f"âš ï¸ {model}: HTTP {response.status_code}")
                
        except Exception as e:
            st.warning(f"âš ï¸ {model}: {str(e)}")
            continue
    
    # ëª¨ë“  GPT-OSS ëª¨ë¸ ì‹¤íŒ¨ì‹œ OpenAI fallback
    st.error("âŒ ëª¨ë“  GPT-OSS ëª¨ë¸ ì‹¤íŒ¨. OpenAI fallback ì‚¬ìš©...")
    try:
        if client:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=500,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        else:
            return "ëª¨ë“  API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"Fallbackë„ ì‹¤íŒ¨: {str(e)}"

def extract_business_card_info(image):
    """ëª…í•¨ ì´ë¯¸ì§€ì—ì„œ ì •ë³´ ì¶”ì¶œ"""
    try:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (PIL ì‚¬ìš©)
        gray_image = image.convert('L')
        
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        width, height = gray_image.size
        if width > 1200:
            ratio = 1200 / width
            new_width = 1200
            new_height = int(height * ratio)
            gray_image = gray_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # OCR ì‹¤í–‰
        text = pytesseract.image_to_string(gray_image, lang='kor+eng')
        
        # GPT-OSSë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ë³´ êµ¬ì¡°í™”
        structured_info = structure_business_card_info(text)
        
        return structured_info
        
    except Exception as e:
        st.error(f"ëª…í•¨ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return None

def structure_business_card_info(raw_text):
    """GPT-OSSë¥¼ ì‚¬ìš©í•˜ì—¬ ëª…í•¨ ì •ë³´ë¥¼ êµ¬ì¡°í™”"""
    try:
        prompt = f"""
ë‹¤ìŒ ëª…í•¨ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:

{raw_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
{{
    "name": "ì´ë¦„",
    "title": "ì§ì±…",
    "company": "íšŒì‚¬ëª…",
    "email": "ì´ë©”ì¼",
    "phone": "ì „í™”ë²ˆí˜¸",
    "mobile": "íœ´ëŒ€í°",
    "address": "ì£¼ì†Œ",
    "website": "ì›¹ì‚¬ì´íŠ¸",
    "department": "ë¶€ì„œ"
}}

ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° nullë¡œ í‘œì‹œí•˜ì„¸ìš”.
"""
        
        # GPT-OSS API í˜¸ì¶œ
        response = call_gpt_oss_api(prompt)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            json_start = response.find('{')
            json_end = response.rfind('}') + 1
            if json_start != -1 and json_end != -1:
                json_str = response[json_start:json_end]
                return json.loads(json_str)
        except:
            pass
        
        # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ë³¸ êµ¬ì¡° ë°˜í™˜
        return {
            "name": "ì¶”ì¶œ ì‹¤íŒ¨",
            "title": None,
            "company": None,
            "email": None,
            "phone": None,
            "mobile": None,
            "address": None,
            "website": None,
            "department": None,
            "raw_text": raw_text,
            "gpt_oss_response": response
        }
        
    except Exception as e:
        return {"error": str(e), "raw_text": raw_text}

def read_pdf(file) -> str:
    """PDF ì½ê¸°"""
    text = ""
    reader = PdfReader(file)
    for page in reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text + "\n"
    return text

def chunk_text(text: str, chunk_size: int = 200, overlap: int = 50):
    """í…ìŠ¤íŠ¸ ì²­í‚¹"""
    words = text.split()
    chunks = []
    start = 0
    while start < len(words):
        chunk = " ".join(words[start : start + chunk_size])
        chunks.append(chunk)
        start += chunk_size - overlap
    return chunks

def get_context(question: str, docs: list) -> str:
    """ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
    if not docs:
        return ""
    
    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­
    question_words = set(question.lower().split())
    best_chunks = []
    
    for i, doc in enumerate(docs[:5]):
        doc_words = set(doc.lower().split())
        overlap = len(question_words.intersection(doc_words))
        if overlap > 0:
            best_chunks.append(doc)
    
    return "\n\n".join(best_chunks[:3]) if best_chunks else docs[0] if docs else ""

def generate_answer(question: str, context: str) -> str:
    """GPT-OSSë¥¼ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±"""
    try:
        if context:
            prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ì°¸ê³  ì •ë³´:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
        else:
            prompt = question
        
        response = call_gpt_oss_api(prompt)
        return response
        
    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

# ë©”ì¸ UI
st.title("ğŸ’¼ GPT-OSS Business Card OCR & PDF Assistant")
st.markdown("**GPT-OSS ê°•ì œ ì‚¬ìš©** - ëª…í•¨ OCRê³¼ PDF ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ")

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ğŸ“‡ ëª…í•¨ OCR", "ğŸ“„ PDF RAG", "ğŸ’¬ ëŒ€í™” ê¸°ë¡"])

with tab1:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.header("ğŸ“‡ ëª…í•¨ OCR (GPT-OSS)")
    st.write("ëª…í•¨ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ GPT-OSSê°€ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    uploaded_image = st.file_uploader(
        "ëª…í•¨ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
        type=['png', 'jpg', 'jpeg'],
        help="ëª…í•¨ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_image is not None:
        image = Image.open(uploaded_image)
        st.image(image, caption="ì—…ë¡œë“œëœ ëª…í•¨", use_column_width=True)
        
        if st.button("ğŸ” GPT-OSSë¡œ ëª…í•¨ ì •ë³´ ì¶”ì¶œ", type="primary"):
            with st.spinner("GPT-OSSê°€ ëª…í•¨ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                card_info = extract_business_card_info(image)
                
                if card_info and "error" not in card_info:
                    # ëª…í•¨ ì •ë³´ë¥¼ ì„¸ì…˜ì— ì €ì¥
                    card_info["timestamp"] = time.strftime("%Y-%m-%d %H:%M:%S")
                    st.session_state.business_cards.append(card_info)
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.markdown('<div class="business-card">', unsafe_allow_html=True)
                    st.subheader("ğŸ“‹ GPT-OSS ì¶”ì¶œ ê²°ê³¼")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        if card_info.get("name"):
                            st.write(f"**ì´ë¦„:** {card_info['name']}")
                        if card_info.get("title"):
                            st.write(f"**ì§ì±…:** {card_info['title']}")
                        if card_info.get("company"):
                            st.write(f"**íšŒì‚¬:** {card_info['company']}")
                        if card_info.get("department"):
                            st.write(f"**ë¶€ì„œ:** {card_info['department']}")
                    
                    with col2:
                        if card_info.get("email"):
                            st.write(f"**ì´ë©”ì¼:** {card_info['email']}")
                        if card_info.get("phone"):
                            st.write(f"**ì „í™”:** {card_info['phone']}")
                        if card_info.get("mobile"):
                            st.write(f"**íœ´ëŒ€í°:** {card_info['mobile']}")
                        if card_info.get("website"):
                            st.write(f"**ì›¹ì‚¬ì´íŠ¸:** {card_info['website']}")
                    
                    if card_info.get("address"):
                        st.write(f"**ì£¼ì†Œ:** {card_info['address']}")
                    
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    st.success("âœ… GPT-OSSê°€ ëª…í•¨ ì •ë³´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error("GPT-OSS ëª…í•¨ ì •ë³´ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    # ì €ì¥ëœ ëª…í•¨ ëª©ë¡
    if st.session_state.business_cards:
        st.subheader("ğŸ“š ì €ì¥ëœ ëª…í•¨ ëª©ë¡")
        for i, card in enumerate(st.session_state.business_cards):
            with st.expander(f"ëª…í•¨ {i+1}: {card.get('name', 'Unknown')} - {card.get('company', 'Unknown')}"):
                st.json(card)
    st.markdown('</div>', unsafe_allow_html=True)

with tab2:
    st.markdown('<div class="pdf-section">', unsafe_allow_html=True)
    st.header("ğŸ“„ PDF RAG (GPT-OSS)")
    st.write("PDFë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•˜ë©´ GPT-OSSê°€ ë‹µë³€í•©ë‹ˆë‹¤.")
    
    uploaded_pdf = st.file_uploader(
        "PDF íŒŒì¼ ì—…ë¡œë“œ",
        type=['pdf'],
        help="PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    if uploaded_pdf is not None:
        with st.spinner("PDFë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            pdf_text = read_pdf(uploaded_pdf)
            if pdf_text:
                chunks = chunk_text(pdf_text)
                st.session_state.pdf_docs = chunks
                st.success(f"âœ… PDF ì²˜ë¦¬ ì™„ë£Œ! {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
                
                # PDF ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ğŸ“– PDF ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°"):
                    st.text_area("PDF ë‚´ìš©", pdf_text[:1000] + "...", height=200, disabled=True)
    
    # ì§ˆë¬¸ ì…ë ¥
    if st.session_state.pdf_docs:
        st.subheader("ğŸ’¬ PDFì— ëŒ€í•´ GPT-OSSì—ê²Œ ì§ˆë¬¸í•˜ê¸°")
        
        question = st.text_input(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:",
            placeholder="PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."
        )
        
        if st.button("ğŸ¤– GPT-OSS ë‹µë³€ ìƒì„±", type="primary") and question:
            with st.spinner("GPT-OSSê°€ ë‹µë³€ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
                context = get_context(question, st.session_state.pdf_docs)
                
                # GPT-OSS ë‹µë³€ ìƒì„±
                answer = generate_answer(question, context)
                
                # ëŒ€í™” ê¸°ë¡ì— ì €ì¥
                conversation_entry = {
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                    "question": question,
                    "answer": answer,
                    "context": context[:200] + "..." if len(context) > 200 else context
                }
                st.session_state.conversation_history.append(conversation_entry)
                
                # ë‹µë³€ í‘œì‹œ
                st.markdown('<div class="card">', unsafe_allow_html=True)
                st.subheader("ğŸ¤– GPT-OSS ë‹µë³€")
                st.write(answer)
                
                if context:
                    with st.expander("ğŸ“„ ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸"):
                        st.text(context)
                
                st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.info("ğŸ“„ PDFë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    st.markdown('</div>', unsafe_allow_html=True)

with tab3:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.header("ğŸ’¬ GPT-OSS ëŒ€í™” ê¸°ë¡")
    
    if st.session_state.conversation_history:
        for i, entry in enumerate(reversed(st.session_state.conversation_history)):
            with st.expander(f"ëŒ€í™” {len(st.session_state.conversation_history) - i}: {entry['question'][:50]}..."):
                st.write(f"**ì§ˆë¬¸:** {entry['question']}")
                st.write(f"**GPT-OSS ë‹µë³€:** {entry['answer']}")
                st.write(f"**ì‹œê°„:** {entry['timestamp']}")
                
                if entry.get('context'):
                    with st.expander("ì»¨í…ìŠ¤íŠ¸"):
                        st.text(entry['context'])
    else:
        st.info("ì•„ì§ GPT-OSS ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
        st.session_state.conversation_history = []
        st.rerun()
    st.markdown('</div>', unsafe_allow_html=True)

# ì‚¬ì´ë“œë°” í†µê³„
with st.sidebar:
    st.header("ğŸ“Š GPT-OSS í†µê³„")
    
    # ëª…í•¨ í†µê³„
    st.subheader("ğŸ“‡ ëª…í•¨")
    st.metric("ì €ì¥ëœ ëª…í•¨", len(st.session_state.business_cards))
    
    # PDF í†µê³„
    st.subheader("ğŸ“„ PDF")
    if st.session_state.pdf_docs:
        st.metric("ì²­í¬ ìˆ˜", len(st.session_state.pdf_docs))
    else:
        st.metric("ì²­í¬ ìˆ˜", 0)
    
    # ëŒ€í™” í†µê³„
    st.subheader("ğŸ’¬ ëŒ€í™”")
    st.metric("GPT-OSS ëŒ€í™” ìˆ˜", len(st.session_state.conversation_history))
    
    st.markdown("---")
    
    # ê¸°ëŠ¥ ì„¤ëª…
    st.header("ğŸ”§ GPT-OSS ê¸°ëŠ¥")
    st.write("""
    **ğŸ“‡ ëª…í•¨ OCR:**
    - ëª…í•¨ ì´ë¯¸ì§€ ì—…ë¡œë“œ
    - GPT-OSS ì •ë³´ ì¶”ì¶œ
    - êµ¬ì¡°í™”ëœ ë°ì´í„° ì €ì¥
    
    **ğŸ“„ PDF RAG:**
    - PDF ë¬¸ì„œ ì—…ë¡œë“œ
    - í…ìŠ¤íŠ¸ ì²­í‚¹
    - GPT-OSS ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ
    
    **ğŸ’¬ ëŒ€í™” ê¸°ë¡:**
    - GPT-OSS ì§ˆë¬¸-ë‹µë³€ íˆìŠ¤í† ë¦¬
    - ì»¨í…ìŠ¤íŠ¸ ì¶”ì 
    - ë©”ëª¨ë¦¬ ê´€ë¦¬
    """)
